# RAGagent

A simple Retrieval-Augmented Generation (RAG) agent built with LangChain, FAISS, HuggingFace embeddings, and Groqâ€™s LLaMA3-70B model.

This agent indexes a document into a vector store and allows you to ask questions about it. Relevant chunks are retrieved using semantic similarity and passed to the LLM to generate answers.

## ğŸ“„ Features

âœ… Loads and splits a Word document (`.docx`)  
âœ… Embeds and saves chunks to FAISS vectorstore  
âœ… Uses HuggingFace `all-MiniLM-L6-v2` for embeddings  
âœ… Runs Groq LLaMA3-70B for answering questions  
âœ… Interactive CLI with top relevant chunks shown

## ğŸš€ Run

1ï¸âƒ£ Install dependencies:
```bash
pip install -r requirements.txt
